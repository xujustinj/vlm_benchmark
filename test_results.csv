vlm_class,vlm_params,classifier_class,classifier_params,dataset_split,n_way,n_support,n_query,n_episodes,accuracy
ClipVLM,"{""path"": ""openai/clip-vit-base-patch32"", ""num_frames"": 1, ""sample_strat"": ""uniform""}",FewShotClassifier,{},/home/datasets/kinetics_100_split/test.txt,5,10,1,1000,0.83
VTTWINS_SimilarityVLM,{},FewShotClassifier,{},/home/datasets/kinetics_100_split/test.txt,5,10,1,1000,0.759
