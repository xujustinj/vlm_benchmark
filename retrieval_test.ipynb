{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import importlib\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLM and Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = os.environ[\"CONDA_DEFAULT_ENV\"]\n",
    "\n",
    "if ENV == \"videoclip\":\n",
    "    from video_clip.video_clip import VideoClipVLM as VLM\n",
    "    vlm_params = {\n",
    "        \"num_seconds\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        \"sample_strat\": [\"center\", \"start\", \"spread\"]\n",
    "    }\n",
    "\n",
    "elif ENV == \"VLM_MILES\":\n",
    "    from MILES.wrapper import MILES_SimilarityVLM as VLM\n",
    "    vlm_params = {}\n",
    "\n",
    "elif ENV == \"VLM_CLIP\":\n",
    "    from CLIP.CLIPVLM import ClipVLM as VLM\n",
    "    vlm_params = {\n",
    "        \"num_frames\": [1, 2, 3, 4, 6, 8, 10, 20, 50, 100]\n",
    "    }\n",
    "\n",
    "else:\n",
    "    ValueError(ENV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/home/datasets/500p/10s_dataset\"\n",
    "MP4_FOLDER = f\"{DATA_FOLDER}/10s_clips\"\n",
    "TXT_FOLDER = f\"{DATA_FOLDER}/10s_kaldi_texts\"\n",
    "\n",
    "video_names = [name[:-4] for name in os.listdir(MP4_FOLDER) if name.endswith(\".mp4\")]\n",
    "video_names.sort()\n",
    "text_names = [name[:-4] for name in os.listdir(TXT_FOLDER) if name.endswith(\".txt\")]\n",
    "text_names.sort()\n",
    "assert video_names == text_names\n",
    "pair_names = video_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500p\n",
      "82 Video-Text Pairs\n",
      "  0:      Video 1_000.mp4\n",
      "the nurse is on the phone patient is trying to get nurse's attention by touching her arm the nurse in the hall\n",
      "\n",
      "  1:      Video 1_001.mp4\n",
      "is counting up putting on blue gown the\n",
      "\n",
      "  2:      Video 1_002.mp4\n",
      "the patient appears slightly more restless as his leg moves the nurse put\n",
      "\n",
      "  3:      Video 1_003.mp4\n",
      "it's down the patient's arm and holds his hand for a moment as she walks to check on her coworker in the hall who's counting up then returns to the\n",
      "\n",
      "  4:      Video 1_004.mp4\n",
      "patient's bedside resumes looking at her phone and is joined by her clinical colleague who can\n",
      "\n",
      "  5:      Video 1_005.mp4\n",
      "in and checks the foley urinary catheter line draining any urine in the line into the receiving bag\n",
      "\n",
      "  6:      Video 1_006.mp4\n",
      "where she checks the mill leaders that has been collected hello\n",
      "\n",
      "  7:      Video 1_007.mp4\n",
      "staff clinician observes and holds the restrain or mitten protocol the points\n",
      "\n",
      "  8:      Video 1_008.mp4\n",
      "to the patient passes picks up the suction tube the\n",
      "\n",
      "  9:      Video 1_009.mp4\n",
      "puts down the mitten and hands the patient the suction to list the suction tube with the help of the page or on behalf of the patient\n",
      "\n",
      " 10:      Video 1_010.mp4\n",
      "the conversation with fellow nurse regarding\n",
      "\n",
      " 11:      Video 1_011.mp4\n",
      "the restraining mitton the nurse had the patient's hand and checks the engine\n",
      "\n",
      " 12:      Video 1_012.mp4\n",
      "two and b tape on the end on the nose\n",
      "\n",
      " 13:      Video 1_013.mp4\n",
      "the phlebotomist pulls up outside the door checking her orders on her phone\n",
      "\n",
      " 14:      Video 1_014.mp4\n",
      "hello nurse goes back to checking urinary catheter catching bag or receiving bag\n",
      "\n",
      " 15:      Video 1_015.mp4\n",
      "communicates with the patient he holds his hand checks be ivey dressing\n",
      "\n",
      " 16:      Video 1_016.mp4\n",
      "to make sure it's secure possibly the patient resume is moving his leg\n",
      "\n",
      " 17:      Video 1_017.mp4\n",
      "it's the nurse othello condition i fixes the strap on the mitten\n",
      "\n",
      " 18:      Video 1_018.mp4\n",
      "the nurse\n",
      "\n",
      " 19:      Video 1_019.mp4\n",
      "walks over to the corner of the screen while the feni waits patiently at the patient's bedside nurse returns to the patient's bedside with\n",
      "\n",
      " 20:      Video 1_020.mp4\n",
      "catching cut the nurse drains urine from the urinary\n",
      "\n",
      " 21:      Video 1_021.mp4\n",
      "after receiver into the catching cup\n",
      "\n",
      " 22:      Video 1_022.mp4\n",
      "the dna holds the patient's hand lobotomies once again in the hall\n",
      "\n",
      " 23:      Video 1_023.mp4\n",
      "and gowned up the nurse finishes emptying out\n",
      "\n",
      " 24:      Video 1_024.mp4\n",
      "the urinary catheter bag talks to the patient for a moment\n",
      "\n",
      " 25:      Video 1_025.mp4\n",
      "the holding the urine walking in the nurse walks off screen to empty the urine\n",
      "\n",
      " 26:      Video 1_026.mp4\n",
      "\n",
      "\n",
      " 27:      Video 2_000.mp4\n",
      "the nurses at the charging station  patient\n",
      "\n",
      " 28:      Video 2_001.mp4\n",
      "sleeping in the bed calm nurse observes the ivy lane and walks back to the side of the patient\n",
      "\n",
      " 29:      Video 2_002.mp4\n",
      "grabs the stethoscope the nurse listens to the different\n",
      "\n",
      " 30:      Video 2_003.mp4\n",
      "chambers of the heart the removes the stethoscope returns to the charging station\n",
      "\n",
      " 31:      Video 2_004.mp4\n",
      "the\n",
      "\n",
      " 32:      Video 2_005.mp4\n",
      "the\n",
      "\n",
      " 33:      Video 2_006.mp4\n",
      "the\n",
      "\n",
      " 34:      Video 2_007.mp4\n",
      "the nurse replaces the stethoscope on a different wall then walks to the side to be\n",
      "\n",
      " 35:      Video 2_008.mp4\n",
      "fusion pump blocks back to the patience fide the\n",
      "\n",
      " 36:      Video 2_009.mp4\n",
      "does the tracheal suctioning too the\n",
      "\n",
      " 37:      Video 2_010.mp4\n",
      "the\n",
      "\n",
      " 38:      Video 2_011.mp4\n",
      "the patient is more restless moving is the\n",
      "\n",
      " 39:      Video 2_012.mp4\n",
      "right leg as the nurse continues charting at a charging station\n",
      "\n",
      " 40:      Video 2_013.mp4\n",
      "the\n",
      "\n",
      " 41:      Video 3_000.mp4\n",
      "first is removing patient's gown nurse is preparing cleaning supplies and\n",
      "\n",
      " 42:      Video 3_001.mp4\n",
      "cleaning urinary catheter the\n",
      "\n",
      " 43:      Video 3_002.mp4\n",
      "the picking up supplies and pudding\n",
      "\n",
      " 44:      Video 3_003.mp4\n",
      "off screen opening up more bringing supplies to buy four swabs or four by four slabs\n",
      "\n",
      " 45:      Video 3_004.mp4\n",
      "the cleaning urinary catheter around the urinary catheter insertion site\n",
      "\n",
      " 46:      Video 3_005.mp4\n",
      "the opening of the stout lock\n",
      "\n",
      " 47:      Video 3_006.mp4\n",
      "placing stout lock on the thigh snapping fully called urinary catheter into the stout lock\n",
      "\n",
      " 48:      Video 3_007.mp4\n",
      "checking bandage at the neck\n",
      "\n",
      " 49:      Video 3_008.mp4\n",
      "the checking skin quality under leg band\n",
      "\n",
      " 50:      Video 3_009.mp4\n",
      "which walking off screen the\n",
      "\n",
      " 51:      Video 3_010.mp4\n",
      "\n",
      "\n",
      " 52:      Video 4_000.mp4\n",
      "clinician is over by the sink wedding the mouth swab klinische and walks to the patient\n",
      "\n",
      " 53:      Video 4_001.mp4\n",
      "the and now he is wedding the patients' lives\n",
      "\n",
      " 54:      Video 4_002.mp4\n",
      "and wedding the side of the cheek and wedding the teeth cleaning bacteria off of the teeth and moving\n",
      "\n",
      " 55:      Video 4_003.mp4\n",
      "to the back disconnecting the mouth swab taking the mouse quotes\n",
      "\n",
      " 56:      Video 4_004.mp4\n",
      "bob offscreen going back to the sink\n",
      "\n",
      " 57:      Video 5_000.mp4\n",
      "someone just walked into the room there to the side of the bed looks like they just untied restraints on the patient he is now raising the bed and someone else came into the room\n",
      "\n",
      " 58:      Video 5_001.mp4\n",
      "he walked away from the bed she's putting gloves on her hands he got a pillow he's putting the bag down\n",
      "\n",
      " 59:      Video 5_002.mp4\n",
      "the infusion pump is moved there both to the side of the dead now restraints are undone she's undoing the restraint now on the other side\n",
      "\n",
      " 60:      Video 5_003.mp4\n",
      "it he is getting ready to place a pillow under the patient side she moved one pillow\n",
      "\n",
      " 61:      Video 5_004.mp4\n",
      "she's now pulling the side over so he can place that pill up there yeah now two pillars are being put\n",
      "\n",
      " 62:      Video 5_005.mp4\n",
      "under the patient yeah and they're putting that back down the adjusting the patient\n",
      "\n",
      " 63:      Video 5_006.mp4\n",
      "and putting the head all the way down then raising the end of the bed getting ready to\n",
      "\n",
      " 64:      Video 5_007.mp4\n",
      "mesmo now the two of them are going to lift him up to the top of the bag\n",
      "\n",
      " 65:      Video 5_008.mp4\n",
      "and that's what they just stared now they're adjusting another pillow he is lowering the end of the bad\n",
      "\n",
      " 66:      Video 5_009.mp4\n",
      "the now it's flout the he is raising a little bit\n",
      "\n",
      " 67:      Video 5_010.mp4\n",
      "i headed to bed one of the people left the room\n",
      "\n",
      " 68:      Video 5_011.mp4\n",
      "he's making adjustments on the patient  now he's going to the other side of the bed\n",
      "\n",
      " 69:      Video 5_012.mp4\n",
      "you can see the sectioning to all he's putting his hand on a blanket adjusting the gown\n",
      "\n",
      " 70:      Video 5_013.mp4\n",
      "he's coming back to the other side of he went to the end the though his giving wanted to the patient\n",
      "\n",
      " 71:      Video 5_014.mp4\n",
      "he got a cup of water something the\n",
      "\n",
      " 72:      Video 5_015.mp4\n",
      "and he finished snout and walked away the he still at the end of the bed\n",
      "\n",
      " 73:      Video 5_016.mp4\n",
      "the turnaround during the patient the adjusting day restraints\n",
      "\n",
      " 74:      Video 5_017.mp4\n",
      "the tying it back down the\n",
      "\n",
      " 75:      Video 5_018.mp4\n",
      "please finish in time the restraints now he's coming to the other side of the bed\n",
      "\n",
      " 76:      Video 5_019.mp4\n",
      "he's getting the restraint on the side he adjusting the patient again\n",
      "\n",
      " 77:      Video 5_020.mp4\n",
      "i mean they had a bit in his time the restraint to the side of the bed\n",
      "\n",
      " 78:      Video 5_021.mp4\n",
      "the when he's done without he now walks around the bed going over\n",
      "\n",
      " 79:      Video 5_022.mp4\n",
      "the computer to do something on the computer\n",
      "\n",
      " 80:      Video 5_023.mp4\n",
      "the he keeps working on the computer the\n",
      "\n",
      " 81:      Video 5_024.mp4\n",
      "when he's walking out of the room the patience in the bed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = \"500p\"\n",
    "\n",
    "if DATASET_ID == \"500p\":\n",
    "    N = len(pair_names)\n",
    "    vid_paths = np.array([f\"{MP4_FOLDER}/{name}.mp4\" for name in pair_names])\n",
    "    vid_text = []\n",
    "    for name in pair_names:\n",
    "        text_path = f\"{TXT_FOLDER}/{name}.txt\"\n",
    "        with open(text_path, \"r\") as fp:\n",
    "            vid_text.append(fp.read().lower().strip())\n",
    "    vid_text = np.array(vid_text)\n",
    "\n",
    "elif DATASET_ID == \"500p.text_overflow_1_1\":\n",
    "    N = len(pair_names)\n",
    "    vid_paths = np.array([f\"{MP4_FOLDER}/{name}.mp4\" for name in pair_names])\n",
    "    raw_vid_text = []\n",
    "    for name in pair_names:\n",
    "        text_path = f\"{TXT_FOLDER}/{name}.txt\"\n",
    "        with open(text_path, \"r\") as fp:\n",
    "            raw_vid_text.append(fp.read().lower().strip())\n",
    "    vid_text = []\n",
    "    for i in range(len(raw_vid_text)):\n",
    "        vid_text.append(\" \".join(raw_vid_text[max(0, i - 1) : min(len(raw_vid_text), i + 2)]))\n",
    "    vid_text = np.array(vid_text)\n",
    "\n",
    "else:\n",
    "    raise ValueError(DATASET_ID)\n",
    "\n",
    "print(DATASET_ID)\n",
    "print(f\"{N} Video-Text Pairs\")\n",
    "for i in range(N):\n",
    "    print(f\"{i:>3}: {vid_paths[i].split('/')[-1]:>20}\")\n",
    "    print(vid_text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Tester Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"retrieval_results.csv\"):\n",
    "    results = pd.read_csv(\"retrieval_results.csv\")\n",
    "else:\n",
    "    results = pd.DataFrame(columns=[\"vlm_class\", \"vlm_params\", \"dataset\",\n",
    "                                    \"R@1 (of 82)\", \"R@5 (of 82)\", \"R@10 (of 82)\", \"R@20 (of 82)\", \"R@50 (of 82)\",\n",
    "                                    \"Mean R\", \"Med R\",\n",
    "                                    \"Ranked Text Indices\", \"Vid-Text Choice Ranks\",\n",
    "                                    \"Correct Vid-Text Pair Ranks\", \"Vid-Text Pairs (Easy->Hard)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_test(vlm):    \n",
    "    pbar = trange(2 * N, leave=False)\n",
    "    vid_embeds = []\n",
    "    text_embeds = []\n",
    "    for path in vid_paths:\n",
    "        vid_embeds.append(vlm.get_video_embeds(path))\n",
    "        pbar.update(1)\n",
    "    for text in vid_text:\n",
    "        text_embeds.append(vlm.get_text_embeds(text))\n",
    "        pbar.update(1)\n",
    "    vid_embeds = np.array(vid_embeds)\n",
    "    text_embeds = np.array(text_embeds)\n",
    "    \n",
    "    similarity = vlm.default_similarity_metric()(vid_embeds, text_embeds)\n",
    "    \n",
    "    sorted_text_choice_indices = np.argsort(-similarity, axis=1) # i, j = text index which is the jth best match to video index i\n",
    "    pair_ranks = np.argsort(sorted_text_choice_indices, axis=1) # i, j = rank position of text j for vid i out of all text options (0 = best choice, 81 = worst)\n",
    "    correct_pair_ranks = pair_ranks[np.arange(N), np.arange(N)] # i = rank position of correct pair (vid i - text i) out of all text options (0 = best, 81 = worst)\n",
    "    sorted_pair_indices = np.argsort(correct_pair_ranks) # vid-text pair index with best rank to vid-text pair index with worst rank\n",
    "    \n",
    "    \n",
    "    # R@1\n",
    "    R1_sum = np.sum(correct_pair_ranks < 1)\n",
    "    R1 = R1_sum / N\n",
    "    \n",
    "    # R@5\n",
    "    R5_sum = np.sum(correct_pair_ranks < 5)\n",
    "    R5 = R5_sum / N\n",
    "    \n",
    "    # R@10\n",
    "    R10_sum = np.sum(correct_pair_ranks < 10)\n",
    "    R10 = R10_sum / N\n",
    "    \n",
    "    # R@20\n",
    "    R20_sum = np.sum(correct_pair_ranks < 20)\n",
    "    R20 = R20_sum / N\n",
    "    \n",
    "    # R@50\n",
    "    R50_sum = np.sum(correct_pair_ranks < 50)\n",
    "    R50 = R50_sum / N\n",
    "    \n",
    "    # Mean/Med Rank\n",
    "    mean_R = np.mean(correct_pair_ranks) + 1\n",
    "    med_R = np.median(correct_pair_ranks) + 1\n",
    "    \n",
    "    print(f\"{vlm.__class__.__name__}   {json.dumps(vlm.params())}\")\n",
    "    print(f\"{'R1':>10}{'R5':>10}{'R10':>10}{'R20':>10}{'R50':>10}{'MeanR':>10}{'MedR':>10}\")\n",
    "    print(f\"{R1:10.3f}{R5:10.3f}{R10:10.3f}{R20:10.3f}{R50:10.3f}{mean_R:10.3f}{med_R:10.3f}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # Save results\n",
    "    # Remove any previously-saved versions of this same test\n",
    "    global results\n",
    "    test_spec = {\n",
    "        \"vlm_class\": vlm.__class__.__name__,\n",
    "        \"vlm_params\": vlm.params(),\n",
    "        \"dataset\": DATASET_ID\n",
    "    }\n",
    "    prev_matching_tests = (results[list(test_spec.keys())] == pd.Series(test_spec)).all(axis=1)\n",
    "    if np.any(prev_matching_tests):\n",
    "        results = results[~prev_matching_tests].reset_index(drop=True)\n",
    "        \n",
    "    results.loc[len(results)] = [\n",
    "        test_spec[\"vlm_class\"],\n",
    "        test_spec[\"vlm_params\"],\n",
    "        test_spec[\"dataset\"],\n",
    "        R1_sum, R5_sum, R10_sum, R20_sum, R50_sum,\n",
    "        mean_R, med_R,\n",
    "        sorted_text_choice_indices, pair_ranks,\n",
    "        correct_pair_ranks, sorted_pair_indices\n",
    "    ]\n",
    "    results.to_csv(\"retrieval_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test over all vlm params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vlm_class</th>\n",
       "      <th>vlm_params</th>\n",
       "      <th>dataset</th>\n",
       "      <th>R@1 (of 82)</th>\n",
       "      <th>R@5 (of 82)</th>\n",
       "      <th>R@10 (of 82)</th>\n",
       "      <th>R@20 (of 82)</th>\n",
       "      <th>R@50 (of 82)</th>\n",
       "      <th>Mean R</th>\n",
       "      <th>Med R</th>\n",
       "      <th>Ranked Text Indices</th>\n",
       "      <th>Vid-Text Choice Ranks</th>\n",
       "      <th>Correct Vid-Text Pair Ranks</th>\n",
       "      <th>Vid-Text Pairs (Easy-&gt;Hard)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ClipVLM</td>\n",
       "      <td>{'path': 'openai/clip-vit-base-patch32', 'num_...</td>\n",
       "      <td>500p.text_overflow_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>41.463415</td>\n",
       "      <td>41.5</td>\n",
       "      <td>[[68 70 62 ... 50 80 32]\\n [68 70 62 ... 50 80...</td>\n",
       "      <td>[[28 16 54 ... 75 80 72]\\n [32 17 60 ... 70 80...</td>\n",
       "      <td>[28 17 54 15 39 15 15  3 11 14 24 44 68 76 74 ...</td>\n",
       "      <td>[68 69 58 62  7 70 77 72 63  8 56 74 61 67  9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ClipVLM</td>\n",
       "      <td>{'path': 'openai/clip-vit-base-patch32', 'num_...</td>\n",
       "      <td>500p.text_overflow_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>46</td>\n",
       "      <td>41.378049</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[[68 70 62 ... 50 80 32]\\n [68 70 69 ... 50 80...</td>\n",
       "      <td>[[28 16 55 ... 76 80 72]\\n [30 18 58 ... 70 80...</td>\n",
       "      <td>[28 18 52 15 39 14 13  3 11 13 26 44 68 76 73 ...</td>\n",
       "      <td>[68 69 58 62  7 70 63 72 77 56 61  8  9 67  6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ClipVLM</td>\n",
       "      <td>{'path': 'openai/clip-vit-base-patch32', 'num_...</td>\n",
       "      <td>500p.text_overflow_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>41.353659</td>\n",
       "      <td>41.5</td>\n",
       "      <td>[[68 70 62 ... 50 80 32]\\n [68 70 69 ... 50 80...</td>\n",
       "      <td>[[28 16 54 ... 77 80 72]\\n [30 17 58 ... 70 80...</td>\n",
       "      <td>[28 17 52 16 37 14 14  3 11 13 26 44 68 76 73 ...</td>\n",
       "      <td>[68 69 58  7 62 70 63 72 77 56  8 61  9 67  5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ClipVLM</td>\n",
       "      <td>{'path': 'openai/clip-vit-base-patch32', 'num_...</td>\n",
       "      <td>500p.text_overflow_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>41.426829</td>\n",
       "      <td>41.5</td>\n",
       "      <td>[[68 70 62 ... 50 80 32]\\n [68 70 69 ... 50 80...</td>\n",
       "      <td>[[28 16 55 ... 77 80 72]\\n [29 18 58 ... 70 80...</td>\n",
       "      <td>[28 18 52 15 37 14 14  3 11 13 26 44 67 76 73 ...</td>\n",
       "      <td>[68 69 58  7 70 62 63 72 77 56  8 61  9 67  5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>MILES_SimilarityVLM</td>\n",
       "      <td>{}</td>\n",
       "      <td>500p.text_overflow_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>51</td>\n",
       "      <td>40.512195</td>\n",
       "      <td>42.5</td>\n",
       "      <td>[[62, 68, 63, 69, 67, 61, 18, 3, 75, 23, 2, 19...</td>\n",
       "      <td>[[33, 22, 10, 7, 18, 24, 61, 35, 69, 58, 46, 3...</td>\n",
       "      <td>[33, 28, 12, 7, 18, 19, 60, 32, 67, 57, 47, 26...</td>\n",
       "      <td>[63, 68, 62, 61, 18, 69, 75, 23, 74, 3, 28, 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vlm_class                                         vlm_params  \\\n",
       "90              ClipVLM  {'path': 'openai/clip-vit-base-patch32', 'num_...   \n",
       "91              ClipVLM  {'path': 'openai/clip-vit-base-patch32', 'num_...   \n",
       "92              ClipVLM  {'path': 'openai/clip-vit-base-patch32', 'num_...   \n",
       "93              ClipVLM  {'path': 'openai/clip-vit-base-patch32', 'num_...   \n",
       "94  MILES_SimilarityVLM                                                 {}   \n",
       "\n",
       "                   dataset  R@1 (of 82)  R@5 (of 82)  R@10 (of 82)  \\\n",
       "90  500p.text_overflow_1_1            1            6             9   \n",
       "91  500p.text_overflow_1_1            1            6             9   \n",
       "92  500p.text_overflow_1_1            1            6             9   \n",
       "93  500p.text_overflow_1_1            1            6             9   \n",
       "94  500p.text_overflow_1_1            1            6            11   \n",
       "\n",
       "    R@20 (of 82)  R@50 (of 82)     Mean R  Med R  \\\n",
       "90            23            46  41.463415   41.5   \n",
       "91            22            46  41.378049   40.0   \n",
       "92            22            48  41.353659   41.5   \n",
       "93            22            48  41.426829   41.5   \n",
       "94            23            51  40.512195   42.5   \n",
       "\n",
       "                                  Ranked Text Indices  \\\n",
       "90  [[68 70 62 ... 50 80 32]\\n [68 70 62 ... 50 80...   \n",
       "91  [[68 70 62 ... 50 80 32]\\n [68 70 69 ... 50 80...   \n",
       "92  [[68 70 62 ... 50 80 32]\\n [68 70 69 ... 50 80...   \n",
       "93  [[68 70 62 ... 50 80 32]\\n [68 70 69 ... 50 80...   \n",
       "94  [[62, 68, 63, 69, 67, 61, 18, 3, 75, 23, 2, 19...   \n",
       "\n",
       "                                Vid-Text Choice Ranks  \\\n",
       "90  [[28 16 54 ... 75 80 72]\\n [32 17 60 ... 70 80...   \n",
       "91  [[28 16 55 ... 76 80 72]\\n [30 18 58 ... 70 80...   \n",
       "92  [[28 16 54 ... 77 80 72]\\n [30 17 58 ... 70 80...   \n",
       "93  [[28 16 55 ... 77 80 72]\\n [29 18 58 ... 70 80...   \n",
       "94  [[33, 22, 10, 7, 18, 24, 61, 35, 69, 58, 46, 3...   \n",
       "\n",
       "                          Correct Vid-Text Pair Ranks  \\\n",
       "90  [28 17 54 15 39 15 15  3 11 14 24 44 68 76 74 ...   \n",
       "91  [28 18 52 15 39 14 13  3 11 13 26 44 68 76 73 ...   \n",
       "92  [28 17 52 16 37 14 14  3 11 13 26 44 68 76 73 ...   \n",
       "93  [28 18 52 15 37 14 14  3 11 13 26 44 67 76 73 ...   \n",
       "94  [33, 28, 12, 7, 18, 19, 60, 32, 67, 57, 47, 26...   \n",
       "\n",
       "                          Vid-Text Pairs (Easy->Hard)  \n",
       "90  [68 69 58 62  7 70 77 72 63  8 56 74 61 67  9 ...  \n",
       "91  [68 69 58 62  7 70 63 72 77 56 61  8  9 67  6 ...  \n",
       "92  [68 69 58  7 62 70 63 72 77 56  8 61  9 67  5 ...  \n",
       "93  [68 69 58  7 70 62 63 72 77 56  8 61  9 67  5 ...  \n",
       "94  [63, 68, 62, 61, 18, 69, 75, 23, 74, 3, 28, 22...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46326c609704c19a066b65445bd0e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######USING ATTENTION STYLE:  frozen-in-time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50238978eb034b3f9be3264058144b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MILES_SimilarityVLM   {}\n",
      "        R1        R5       R10       R20       R50     MeanR      MedR\n",
      "     0.012     0.073     0.134     0.280     0.622    40.512    42.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dynamically display most recent test results\n",
    "disp = display(display_id=True)\n",
    "disp.update(results.tail(5))\n",
    "\n",
    "vlm = None\n",
    "if len(vlm_params):\n",
    "    param_list = tqdm(list(itertools.product(*vlm_params.values())))\n",
    "else:\n",
    "    param_list = tqdm([[]])\n",
    "    \n",
    "for params in param_list:\n",
    "    params = dict(zip(vlm_params.keys(), params))\n",
    "    param_list.set_postfix(params)\n",
    "    \n",
    "    vlm = VLM(**params)\n",
    "    \n",
    "    retrieval_test(vlm)\n",
    "    disp.update(results.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.66666667 46.66666667  8.66666667 15.33333333  7.66666667 32.\n",
      " 63.         37.33333333 20.33333333 31.         25.33333333 19.66666667\n",
      " 70.         59.66666667 24.33333333 23.         20.66666667 62.66666667\n",
      " 30.33333333 20.33333333 38.33333333 67.         24.66666667 21.\n",
      " 15.         37.66666667 63.         17.         35.66666667 31.66666667\n",
      " 37.66666667 58.66666667 63.66666667 65.66666667 23.33333333 55.\n",
      " 61.66666667 62.66666667 14.33333333 15.33333333 59.         14.66666667\n",
      " 48.66666667 64.33333333 69.66666667 42.33333333 80.         56.\n",
      " 41.66666667 60.33333333 62.66666667 56.         30.33333333 30.\n",
      " 63.66666667 59.33333333 59.66666667  3.66666667 31.66666667 24.33333333\n",
      "  8.66666667 44.33333333  6.         27.         53.66666667 17.33333333\n",
      " 51.         41.33333333  1.66666667 23.         25.66666667 64.33333333\n",
      " 47.         25.         52.         24.66666667 21.         33.33333333\n",
      " 40.         62.66666667 57.33333333 39.        ]\n",
      "[68 57 62  4  2 60 38 41 24  3 39  0 27 65 11  8 19 16 23 76 69 15 34 59\n",
      " 14 22 75 73 10 70 63 53 18 52  9 29 58  5 77 28  7 25 30 20 81 78 67 48\n",
      " 45 61  1 72 42 66 74 64 35 47 51 80 31 40 55 56 13 49 36 79 37 17 50 26\n",
      "  6 32 54 71 43 33 21 44 12 46]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for x in results[\"Correct Vid-Text Pair Ranks\"][[3, 30, 40]].values:\n",
    "    test.append([int(rank) for rank in x.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\", \"\").split()])\n",
    "test = np.array(test)\n",
    "test = np.mean(test, axis=0)\n",
    "print(test)\n",
    "print(np.argsort(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VLM_MILES')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa12131d24cc94205087ad381a7dfdae34f6e827b859c030f23450f0750c1ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
