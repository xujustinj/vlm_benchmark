{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import importlib\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from SimilarityVLM import SimilarityVLM\n",
    "from dataset.dataset import FewShotTaskDataset, SequentialVideoDataset, SequentialCategoryNameDataset\n",
    "from FewShotClassifier import FewShotClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose VLM to Test\n",
    "\n",
    "Note, this notebook must be run using the corresponding conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VLM = importlib.import_module(\"VT-TWINS.wrapper\").VTTWINS_SimilarityVLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Dataset to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SPLIT_PATH = \"/home/datasets/kinetics_100_split/test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Few-Shot Task Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 5                       # Number of categories to choose between in each task\n",
    "N_SUPPORT = 10                  # Number of example videos per category per task\n",
    "N_QUERY = 1                     # Number of test videos per category per task\n",
    "N_EPISODES = 1000               # Number of few-shot tasks sampled in one iteration of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VLM Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VLM and Few-Shot Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm = VLM(reset_cache=False)\n",
    "classifier = FewShotClassifier(vlm, metric=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55b4b045c2944c49ee3159a4ec6763c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/vlm_benchmark/VT-TWINS/VT-TWINS/loader/msrvtt_loader.py:88: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352660876/work/torch/csrc/utils/tensor_numpy.cpp:172.)\n",
      "  video = th.from_numpy(video)\n"
     ]
    }
   ],
   "source": [
    "video_dataset = SequentialVideoDataset(DATASET_SPLIT_PATH)\n",
    "\n",
    "try:\n",
    "    for vid_path in tqdm(video_dataset):\n",
    "        if vid_path not in vlm.embed_cache:\n",
    "            vlm.get_video_embeds(vid_path)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    vlm.save_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup DataFrame for Saving Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RESULTS_PATH = \"test_results.csv\"\n",
    "TEST_RESULTS_COLUMNS = [\"vlm_class\", \"classifier_class\", \"dataset_split\", \"n_way\", \"n_support\", \"n_query\", \"n_episodes\", \"accuracy\"]\n",
    "\n",
    "if os.path.exists(TEST_RESULTS_PATH):\n",
    "    test_results = pd.read_csv(TEST_RESULTS_PATH)\n",
    "else:\n",
    "    test_results = pd.DataFrame(columns=TEST_RESULTS_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_accuracy(classifier: FewShotClassifier, dataset_split_path: str,\n",
    "                      n_way: int, n_support: int, n_query: int = 1, n_episodes: int = 1000,\n",
    "                      test_results_df: pd.DataFrame = None) -> float:\n",
    "    \n",
    "    # Load dataset to generate tasks with the desired params\n",
    "    dataset = FewShotTaskDataset(dataset_split_path, n_episodes, n_way, n_support, n_query)\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_queries = 0\n",
    "    for vid_paths, category_names in tqdm(dataset):\n",
    "        \n",
    "        query_vid_paths = vid_paths[:, n_support:]\n",
    "        if n_support > 0:\n",
    "            support_vid_paths = vid_paths[:, :n_support]\n",
    "        else:\n",
    "            support_vid_paths = None\n",
    "            \n",
    "        query_predictions = classifier.predict(category_names, support_vid_paths, query_vid_paths)\n",
    "        \n",
    "        correct_predictions += np.sum(query_predictions == np.arange(n_way)[:, None])\n",
    "        total_queries += n_way * n_query\n",
    "        \n",
    "    accuracy = correct_predictions / total_queries\n",
    "    \n",
    "    # Save into test_results df if existing\n",
    "    if test_results_df is not None:\n",
    "        df_row = {\n",
    "            \"vlm_class\": [classifier.vlm.__class__.__name__],\n",
    "            \"classifier_class\": [classifier.__class__.__name__],\n",
    "            \"dataset_split\": [dataset_split_path],\n",
    "            \"n_way\": [n_way],\n",
    "            \"n_support\": [n_support],\n",
    "            \"n_query\": [n_query],\n",
    "            \"n_episodes\": [n_episodes],\n",
    "            \"accuracy\": [accuracy]\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return correct_predictions / total_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_accuracy(classifier, DATASET_SPLIT_PATH, n_way=N_WAY, n_support=N_SUPPORT, n_query=N_QUERY, n_episodes=N_EPISODES, test_results_df=test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Updated Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.to_csv(TEST_RESULTS_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VLM_VTTWINS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "531e74653c30fadb69f06333bfe9aca829cdb42de2b584f8d92e169bb9dc6b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
